// Signature file for parser generated by fsyacc
module SqlParser
type token = 
  | EOF
  | DOT
  | COMMA
  | EQ
  | LT
  | LE
  | GT
  | GE
  | NEQ
  | ASC
  | DESC
  | AND
  | OR
  | ON
  | JOIN
  | INNER
  | LEFT
  | RIGHT
  | SELECT
  | FROM
  | WHERE
  | ORDER
  | BY
  | BOOL of (bool)
  | STRING of (string)
  | INT of (int)
type tokenId = 
    | TOKEN_EOF
    | TOKEN_DOT
    | TOKEN_COMMA
    | TOKEN_EQ
    | TOKEN_LT
    | TOKEN_LE
    | TOKEN_GT
    | TOKEN_GE
    | TOKEN_NEQ
    | TOKEN_ASC
    | TOKEN_DESC
    | TOKEN_AND
    | TOKEN_OR
    | TOKEN_ON
    | TOKEN_JOIN
    | TOKEN_INNER
    | TOKEN_LEFT
    | TOKEN_RIGHT
    | TOKEN_SELECT
    | TOKEN_FROM
    | TOKEN_WHERE
    | TOKEN_ORDER
    | TOKEN_BY
    | TOKEN_BOOL
    | TOKEN_STRING
    | TOKEN_INT
    | TOKEN_end_of_input
    | TOKEN_error
type nonTerminalId = 
    | NONTERM__startstart
    | NONTERM_start
/// This function maps tokens to integer indexes
val tagOfToken: token -> int

/// This function maps integer indexes to symbolic token ids
val tokenTagToTokenId: int -> tokenId

/// This function maps production indexes returned in syntax errors to strings representing the non terminal that would be produced by that production
val prodIdxToNonTerminal: int -> nonTerminalId

/// This function gets the name of a token as a string
val token_to_string: token -> string
val start : (Microsoft.FSharp.Text.Lexing.LexBuffer<'cty> -> token) -> Microsoft.FSharp.Text.Lexing.LexBuffer<'cty> -> (Int32) 
